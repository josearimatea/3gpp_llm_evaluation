{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4,
  "eval_steps": 500,
  "global_step": 150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 1.1779676675796509,
      "learning_rate": 4e-05,
      "loss": 1.7554,
      "step": 1
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.1981481313705444,
      "learning_rate": 8e-05,
      "loss": 1.795,
      "step": 2
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.178970456123352,
      "learning_rate": 0.00012,
      "loss": 1.6159,
      "step": 3
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.2041479349136353,
      "learning_rate": 0.00016,
      "loss": 1.5085,
      "step": 4
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4692350625991821,
      "learning_rate": 0.0002,
      "loss": 1.4737,
      "step": 5
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.9795082211494446,
      "learning_rate": 0.00019862068965517243,
      "loss": 1.0093,
      "step": 6
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.4913758933544159,
      "learning_rate": 0.00019724137931034484,
      "loss": 1.23,
      "step": 7
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.37414249777793884,
      "learning_rate": 0.00019586206896551723,
      "loss": 1.1138,
      "step": 8
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.32851642370224,
      "learning_rate": 0.00019448275862068965,
      "loss": 1.0801,
      "step": 9
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5934054851531982,
      "learning_rate": 0.0001931034482758621,
      "loss": 1.1364,
      "step": 10
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.34499478340148926,
      "learning_rate": 0.0001917241379310345,
      "loss": 0.7544,
      "step": 11
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.32605043053627014,
      "learning_rate": 0.0001903448275862069,
      "loss": 0.7932,
      "step": 12
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.3528296649456024,
      "learning_rate": 0.00018896551724137932,
      "loss": 1.1399,
      "step": 13
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3313586115837097,
      "learning_rate": 0.00018758620689655173,
      "loss": 0.9928,
      "step": 14
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3274710476398468,
      "learning_rate": 0.00018620689655172415,
      "loss": 0.9857,
      "step": 15
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3382256031036377,
      "learning_rate": 0.00018482758620689654,
      "loss": 0.9504,
      "step": 16
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.29286906123161316,
      "learning_rate": 0.00018344827586206896,
      "loss": 0.855,
      "step": 17
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.26041853427886963,
      "learning_rate": 0.0001820689655172414,
      "loss": 0.7386,
      "step": 18
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.3692443072795868,
      "learning_rate": 0.00018068965517241382,
      "loss": 1.1183,
      "step": 19
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37787047028541565,
      "learning_rate": 0.0001793103448275862,
      "loss": 0.9723,
      "step": 20
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3014410138130188,
      "learning_rate": 0.00017793103448275862,
      "loss": 0.9736,
      "step": 21
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.41476479172706604,
      "learning_rate": 0.00017655172413793104,
      "loss": 0.9615,
      "step": 22
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.3183571398258209,
      "learning_rate": 0.00017517241379310346,
      "loss": 0.8115,
      "step": 23
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.34240689873695374,
      "learning_rate": 0.00017379310344827587,
      "loss": 1.0328,
      "step": 24
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3039093017578125,
      "learning_rate": 0.00017241379310344826,
      "loss": 0.9066,
      "step": 25
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.3191166818141937,
      "learning_rate": 0.0001710344827586207,
      "loss": 1.0844,
      "step": 26
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.3095075786113739,
      "learning_rate": 0.00016965517241379312,
      "loss": 1.0357,
      "step": 27
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.28943249583244324,
      "learning_rate": 0.00016827586206896554,
      "loss": 0.6701,
      "step": 28
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.3450203239917755,
      "learning_rate": 0.00016689655172413793,
      "loss": 1.1016,
      "step": 29
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.27881231904029846,
      "learning_rate": 0.00016551724137931035,
      "loss": 0.8666,
      "step": 30
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.36159172654151917,
      "learning_rate": 0.00016413793103448276,
      "loss": 0.8516,
      "step": 31
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.32479628920555115,
      "learning_rate": 0.00016275862068965518,
      "loss": 1.0186,
      "step": 32
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.43454626202583313,
      "learning_rate": 0.0001613793103448276,
      "loss": 1.2612,
      "step": 33
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.2913656234741211,
      "learning_rate": 0.00016,
      "loss": 0.8249,
      "step": 34
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.30668628215789795,
      "learning_rate": 0.00015862068965517243,
      "loss": 0.7973,
      "step": 35
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.2862425744533539,
      "learning_rate": 0.00015724137931034485,
      "loss": 0.9877,
      "step": 36
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.263672798871994,
      "learning_rate": 0.00015586206896551724,
      "loss": 0.7981,
      "step": 37
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2737390398979187,
      "learning_rate": 0.00015448275862068965,
      "loss": 0.8251,
      "step": 38
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.393291711807251,
      "learning_rate": 0.00015310344827586207,
      "loss": 1.0424,
      "step": 39
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2923906147480011,
      "learning_rate": 0.00015172413793103449,
      "loss": 0.7633,
      "step": 40
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.30008330941200256,
      "learning_rate": 0.0001503448275862069,
      "loss": 1.0509,
      "step": 41
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.33438077569007874,
      "learning_rate": 0.00014896551724137932,
      "loss": 0.9494,
      "step": 42
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.34148675203323364,
      "learning_rate": 0.00014758620689655174,
      "loss": 1.1097,
      "step": 43
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3010514974594116,
      "learning_rate": 0.00014620689655172415,
      "loss": 0.8819,
      "step": 44
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3552398681640625,
      "learning_rate": 0.00014482758620689657,
      "loss": 1.048,
      "step": 45
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3935079872608185,
      "learning_rate": 0.00014344827586206896,
      "loss": 1.1741,
      "step": 46
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.4532277584075928,
      "learning_rate": 0.00014206896551724138,
      "loss": 0.818,
      "step": 47
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.3042525351047516,
      "learning_rate": 0.0001406896551724138,
      "loss": 1.0268,
      "step": 48
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.3042876422405243,
      "learning_rate": 0.0001393103448275862,
      "loss": 0.9341,
      "step": 49
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3101802468299866,
      "learning_rate": 0.00013793103448275863,
      "loss": 1.0253,
      "step": 50
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.3322308361530304,
      "learning_rate": 0.00013655172413793104,
      "loss": 1.0906,
      "step": 51
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.35019901394844055,
      "learning_rate": 0.00013517241379310346,
      "loss": 0.9119,
      "step": 52
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.27668535709381104,
      "learning_rate": 0.00013379310344827588,
      "loss": 0.7564,
      "step": 53
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.34000542759895325,
      "learning_rate": 0.0001324137931034483,
      "loss": 0.9372,
      "step": 54
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3114943206310272,
      "learning_rate": 0.00013103448275862068,
      "loss": 0.966,
      "step": 55
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.31141892075538635,
      "learning_rate": 0.0001296551724137931,
      "loss": 0.9492,
      "step": 56
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.2651841342449188,
      "learning_rate": 0.00012827586206896552,
      "loss": 0.8245,
      "step": 57
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.31623297929763794,
      "learning_rate": 0.00012689655172413793,
      "loss": 0.842,
      "step": 58
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.30961737036705017,
      "learning_rate": 0.00012551724137931035,
      "loss": 0.9397,
      "step": 59
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.33731383085250854,
      "learning_rate": 0.00012413793103448277,
      "loss": 1.25,
      "step": 60
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.2881174683570862,
      "learning_rate": 0.00012275862068965518,
      "loss": 0.991,
      "step": 61
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2912195324897766,
      "learning_rate": 0.00012137931034482759,
      "loss": 0.6976,
      "step": 62
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.4890190064907074,
      "learning_rate": 0.00012,
      "loss": 1.1602,
      "step": 63
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.28467264771461487,
      "learning_rate": 0.0001186206896551724,
      "loss": 0.7576,
      "step": 64
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.35689160227775574,
      "learning_rate": 0.00011724137931034482,
      "loss": 0.9808,
      "step": 65
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.2608800232410431,
      "learning_rate": 0.00011586206896551725,
      "loss": 0.7641,
      "step": 66
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.28996801376342773,
      "learning_rate": 0.00011448275862068967,
      "loss": 0.89,
      "step": 67
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.3088463544845581,
      "learning_rate": 0.00011310344827586207,
      "loss": 0.7662,
      "step": 68
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.29502564668655396,
      "learning_rate": 0.00011172413793103449,
      "loss": 0.7774,
      "step": 69
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.3129150867462158,
      "learning_rate": 0.0001103448275862069,
      "loss": 0.8706,
      "step": 70
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.2948050796985626,
      "learning_rate": 0.00010896551724137931,
      "loss": 0.8296,
      "step": 71
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.31470370292663574,
      "learning_rate": 0.00010758620689655173,
      "loss": 0.9244,
      "step": 72
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.32066601514816284,
      "learning_rate": 0.00010620689655172413,
      "loss": 0.8289,
      "step": 73
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.3197520077228546,
      "learning_rate": 0.00010482758620689656,
      "loss": 0.8159,
      "step": 74
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.34311437606811523,
      "learning_rate": 0.00010344827586206898,
      "loss": 0.7891,
      "step": 75
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.3632943630218506,
      "learning_rate": 0.0001020689655172414,
      "loss": 1.0157,
      "step": 76
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.37968435883522034,
      "learning_rate": 0.0001006896551724138,
      "loss": 1.1234,
      "step": 77
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.3286125063896179,
      "learning_rate": 9.931034482758621e-05,
      "loss": 0.7416,
      "step": 78
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.3295709192752838,
      "learning_rate": 9.793103448275862e-05,
      "loss": 0.8448,
      "step": 79
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.331557959318161,
      "learning_rate": 9.655172413793105e-05,
      "loss": 0.8361,
      "step": 80
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.43757304549217224,
      "learning_rate": 9.517241379310345e-05,
      "loss": 0.7797,
      "step": 81
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.48660919070243835,
      "learning_rate": 9.379310344827587e-05,
      "loss": 1.1995,
      "step": 82
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.3262024521827698,
      "learning_rate": 9.241379310344827e-05,
      "loss": 0.743,
      "step": 83
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.3429403305053711,
      "learning_rate": 9.10344827586207e-05,
      "loss": 0.7272,
      "step": 84
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.3692304193973541,
      "learning_rate": 8.96551724137931e-05,
      "loss": 0.7992,
      "step": 85
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.428960919380188,
      "learning_rate": 8.827586206896552e-05,
      "loss": 0.8683,
      "step": 86
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.3710855543613434,
      "learning_rate": 8.689655172413794e-05,
      "loss": 0.9628,
      "step": 87
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.3372655510902405,
      "learning_rate": 8.551724137931035e-05,
      "loss": 0.705,
      "step": 88
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.3470989763736725,
      "learning_rate": 8.413793103448277e-05,
      "loss": 0.6895,
      "step": 89
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.3625238239765167,
      "learning_rate": 8.275862068965517e-05,
      "loss": 0.7421,
      "step": 90
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.42948779463768005,
      "learning_rate": 8.137931034482759e-05,
      "loss": 0.9103,
      "step": 91
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.3625190258026123,
      "learning_rate": 8e-05,
      "loss": 0.7076,
      "step": 92
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.39743730425834656,
      "learning_rate": 7.862068965517242e-05,
      "loss": 0.8833,
      "step": 93
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.3700655996799469,
      "learning_rate": 7.724137931034483e-05,
      "loss": 0.7198,
      "step": 94
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.3826592266559601,
      "learning_rate": 7.586206896551724e-05,
      "loss": 0.6603,
      "step": 95
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.41519513726234436,
      "learning_rate": 7.448275862068966e-05,
      "loss": 0.872,
      "step": 96
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.3825671374797821,
      "learning_rate": 7.310344827586208e-05,
      "loss": 0.7515,
      "step": 97
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.41856345534324646,
      "learning_rate": 7.172413793103448e-05,
      "loss": 0.8456,
      "step": 98
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.44004565477371216,
      "learning_rate": 7.03448275862069e-05,
      "loss": 0.7571,
      "step": 99
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4437609016895294,
      "learning_rate": 6.896551724137931e-05,
      "loss": 0.8077,
      "step": 100
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.42849430441856384,
      "learning_rate": 6.758620689655173e-05,
      "loss": 0.7571,
      "step": 101
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.4685274660587311,
      "learning_rate": 6.620689655172415e-05,
      "loss": 0.8797,
      "step": 102
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.4373624920845032,
      "learning_rate": 6.482758620689655e-05,
      "loss": 0.8385,
      "step": 103
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.42957255244255066,
      "learning_rate": 6.344827586206897e-05,
      "loss": 0.702,
      "step": 104
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.47857359051704407,
      "learning_rate": 6.206896551724138e-05,
      "loss": 0.8713,
      "step": 105
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.5498894453048706,
      "learning_rate": 6.068965517241379e-05,
      "loss": 1.0162,
      "step": 106
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.44802266359329224,
      "learning_rate": 5.93103448275862e-05,
      "loss": 0.8523,
      "step": 107
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.41869059205055237,
      "learning_rate": 5.7931034482758627e-05,
      "loss": 0.8606,
      "step": 108
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.47212231159210205,
      "learning_rate": 5.6551724137931037e-05,
      "loss": 0.9199,
      "step": 109
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.43266093730926514,
      "learning_rate": 5.517241379310345e-05,
      "loss": 0.8087,
      "step": 110
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.4299498200416565,
      "learning_rate": 5.379310344827586e-05,
      "loss": 0.7972,
      "step": 111
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.34071844816207886,
      "learning_rate": 5.241379310344828e-05,
      "loss": 0.5387,
      "step": 112
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.4968048632144928,
      "learning_rate": 5.10344827586207e-05,
      "loss": 1.0582,
      "step": 113
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.46751782298088074,
      "learning_rate": 4.9655172413793107e-05,
      "loss": 0.8303,
      "step": 114
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.4937218129634857,
      "learning_rate": 4.827586206896552e-05,
      "loss": 0.9427,
      "step": 115
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.4953802227973938,
      "learning_rate": 4.689655172413793e-05,
      "loss": 1.0166,
      "step": 116
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.4782645106315613,
      "learning_rate": 4.551724137931035e-05,
      "loss": 0.9346,
      "step": 117
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.45187708735466003,
      "learning_rate": 4.413793103448276e-05,
      "loss": 0.6902,
      "step": 118
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.4356216490268707,
      "learning_rate": 4.275862068965518e-05,
      "loss": 0.799,
      "step": 119
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.4908713400363922,
      "learning_rate": 4.1379310344827587e-05,
      "loss": 0.8905,
      "step": 120
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.4955331087112427,
      "learning_rate": 4e-05,
      "loss": 0.9512,
      "step": 121
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.40872102975845337,
      "learning_rate": 3.862068965517241e-05,
      "loss": 0.8222,
      "step": 122
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.466973215341568,
      "learning_rate": 3.724137931034483e-05,
      "loss": 0.895,
      "step": 123
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.4502619802951813,
      "learning_rate": 3.586206896551724e-05,
      "loss": 0.8448,
      "step": 124
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6628237962722778,
      "learning_rate": 3.4482758620689657e-05,
      "loss": 1.2584,
      "step": 125
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.46802204847335815,
      "learning_rate": 3.310344827586207e-05,
      "loss": 0.7397,
      "step": 126
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.4239163398742676,
      "learning_rate": 3.172413793103448e-05,
      "loss": 0.7856,
      "step": 127
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.40442290902137756,
      "learning_rate": 3.0344827586206897e-05,
      "loss": 0.7642,
      "step": 128
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.4213408827781677,
      "learning_rate": 2.8965517241379313e-05,
      "loss": 0.8826,
      "step": 129
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.38510775566101074,
      "learning_rate": 2.7586206896551727e-05,
      "loss": 0.764,
      "step": 130
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.4317578077316284,
      "learning_rate": 2.620689655172414e-05,
      "loss": 0.7505,
      "step": 131
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.42476537823677063,
      "learning_rate": 2.4827586206896553e-05,
      "loss": 0.6354,
      "step": 132
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.40117043256759644,
      "learning_rate": 2.3448275862068967e-05,
      "loss": 0.5849,
      "step": 133
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.4119439125061035,
      "learning_rate": 2.206896551724138e-05,
      "loss": 0.6659,
      "step": 134
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.4394450783729553,
      "learning_rate": 2.0689655172413793e-05,
      "loss": 0.9097,
      "step": 135
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.47096681594848633,
      "learning_rate": 1.9310344827586207e-05,
      "loss": 0.7492,
      "step": 136
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.49793344736099243,
      "learning_rate": 1.793103448275862e-05,
      "loss": 0.7945,
      "step": 137
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.45681706070899963,
      "learning_rate": 1.6551724137931037e-05,
      "loss": 0.7223,
      "step": 138
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.36589905619621277,
      "learning_rate": 1.5172413793103448e-05,
      "loss": 0.5111,
      "step": 139
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5148359537124634,
      "learning_rate": 1.3793103448275863e-05,
      "loss": 0.9152,
      "step": 140
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.6123867630958557,
      "learning_rate": 1.2413793103448277e-05,
      "loss": 1.0164,
      "step": 141
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.4966006577014923,
      "learning_rate": 1.103448275862069e-05,
      "loss": 0.8032,
      "step": 142
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.494733601808548,
      "learning_rate": 9.655172413793103e-06,
      "loss": 0.8304,
      "step": 143
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.4915632903575897,
      "learning_rate": 8.275862068965518e-06,
      "loss": 0.8462,
      "step": 144
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5541467070579529,
      "learning_rate": 6.896551724137932e-06,
      "loss": 0.8934,
      "step": 145
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.43902111053466797,
      "learning_rate": 5.517241379310345e-06,
      "loss": 0.7313,
      "step": 146
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.4492824375629425,
      "learning_rate": 4.137931034482759e-06,
      "loss": 0.7109,
      "step": 147
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.41646960377693176,
      "learning_rate": 2.7586206896551725e-06,
      "loss": 0.6339,
      "step": 148
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.4369356632232666,
      "learning_rate": 1.3793103448275862e-06,
      "loss": 0.6806,
      "step": 149
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4601697623729706,
      "learning_rate": 0.0,
      "loss": 0.641,
      "step": 150
    }
  ],
  "logging_steps": 1,
  "max_steps": 150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.351257850546176e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
