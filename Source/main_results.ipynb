{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TSpec-LLM Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is TSpec-LLM\n",
        "The TSpec-LLM Dataset is the dataset that contains 3GPP documents, but they have already been modified and formatted into markdown files to facilitate usage and integration into LLMs. \n",
        "\n",
        "In this project, only 3GPP release 17 was used. The TSpec-LLM dataset was used to perform retrieval using RAG (Retrieval-Augmented Generation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import Process_tspec_llm\n",
        "\n",
        "# processTspec = Process_tspec_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify TSpec-LLM Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory_path = '../Dataset/TSpec-LLM/3GPP-clean'\n",
        "# md_sizes_report = processTspec.calculate_md_sizes_and_word_count(directory_path)\n",
        "# json_filename = 'md_sizes_word_count_report.json'\n",
        "# processTspec.save_report_to_json(md_sizes_report, json_filename)\n",
        "# processTspec.print_summary(md_sizes_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TeleQnA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Questions Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "100 questions to evaluate the models.\n",
        "\n",
        "The questions were evaluated in two ways: \n",
        "\n",
        "1 - The question was asked along with options, and the model was expected to choose the correct option. \n",
        "\n",
        "2 - The question was asked without options, and the model had to answer based solely on the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Path to the TeleQnA processed question in JSON file\n",
        "rel17_100_questions_path = r\"../Files/rel17_100_questions.json\"\n",
        "\n",
        "# Load the TeleQnA data just release 17\n",
        "with open(rel17_100_questions_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    rel17_100_questions = json.load(file)\n",
        "print(len(rel17_100_questions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Which NGAP procedure is used for inter-system load balancing? [3GPP Release 17]',\n",
              " 'option 1': 'eNB Configuration Transfer',\n",
              " 'option 2': 'Downlink RAN Configuration Transfer',\n",
              " 'option 3': 'Uplink RAN Configuration Transfer',\n",
              " 'option 4': 'MME Configuration Transfer',\n",
              " 'answer': 'option 3: Uplink RAN Configuration Transfer',\n",
              " 'explanation': 'The NGAP procedure used for inter-system load balancing is Uplink RAN Configuration Transfer.',\n",
              " 'category': 'Standards overview'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rel17_100_questions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training dataset is also composed of questions from TeleQnA.\n",
        "\n",
        "A total of 4,000 questions were selected from TeleQnA, which are different from the test dataset containing 100 questions.\n",
        "\n",
        "Out of these 4,000 questions, 2,000 had options, with the label being the correct option along with its text, while the other 2,000 questions had no options, with the label being only the text of the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset_path = '../Files/train_questions_dataset_4000_questions_short_answer_labels'\n",
        "\n",
        "dataset = load_from_disk(dataset_path)\n",
        "\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'conversations': [{'from': 'human',\n",
              "   'value': 'Question: Which type of pulse adaptation is equivalent to the dilation of the pulse depending on the channel dispersion in time and frequency?\\nOptions:\\noption 1: Grid adaptation\\noption 2: Pulse adaptation\\noption 3: Uniform spacing adaptation\\noption 4: Rectangular spacing adaptation\\n'},\n",
              "  {'from': 'gpt', 'value': 'Answer: option 2: Pulse adaptation\\n'}]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Three models were evaluated:\n",
        "\n",
        "1 - Llama 3.2 with 3 billion parameters\n",
        "\n",
        "2 - Llama 3.2 with 3 billion parameters with fine-tuning, using 4,000 questions for training\n",
        "\n",
        "3 - GPT-4o-mini\n",
        "\n",
        "The models were evaluated both without RAG and with RAG, where relevant information was provided as context for the question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "from utils.accuracy_evaluator import evaluate_accuracy\n",
        "from utils.load_json import load_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "RAG_llama_3_2_lora_path = \"../Models_responses/Accuracy/llama_3.2_lora_short_answer_RAG_responses.json\"\n",
        "RAG_llama_3_2_path = \"../Models_responses/Accuracy/llama_3.2_RAG_responses.json\"\n",
        "RAG_gpt4_path = \"../Models_responses/Accuracy/gpt4_RAG_responses.json\"\n",
        "llama_3_2_lora_path = \"../Models_responses/Accuracy/llama_3.2_lora_short_answer_responses.json\"\n",
        "llama_3_2_path = \"../Models_responses/Accuracy/llama_3.2_responses.json\"\n",
        "gpt4_path = \"../Models_responses/Accuracy/gpt4_responses.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "RAG_llama_3_2_lora = load_responses(RAG_llama_3_2_lora_path)\n",
        "RAG_llama_3_2 = load_responses(RAG_llama_3_2_path)\n",
        "RAG_gpt4 = load_responses(RAG_gpt4_path)\n",
        "llama_3_2_lora = load_responses(llama_3_2_lora_path)\n",
        "llama_3_2 = load_responses(llama_3_2_path)\n",
        "gpt4 = load_responses(gpt4_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Which NGAP procedure is used for inter-system load balancing? [3GPP Release 17]',\n",
              " 'answer': 'option 3: Uplink RAN Configuration Transfer',\n",
              " 'response': \"system\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nuser\\n\\nRelevant Information:\\nInformation 1:\\nconsider the responses before executing the planned change of its\\nmobility setting.  \\nAll automatic changes on the HO and/or reselection parameters must be\\nwithin the range allowed by OAM.  \\n#### 15.5.1.5 Load reporting for inter-system load balancing  \\nThe load reporting function for inter-system load balancing is executed\\nby exchanging load information between NG-RAN and E-UTRAN. Both\\nevent-triggered and periodic inter-system load reporting are supported.\\nEvent-triggered inter-system load reports are sent when the reporting\\nnode detects crossing of cell load thresholds.  \\nThe following load related information should be supported:  \\n\\\\- Cell Capacity Class value (UL/DL relative capacity indicator);  \\n\\\\- Capacity value (per cell: UL/DL available capacity);  \\n\\\\- RRC connections (number of RRC connections, and available RRC\\nConnection Capacity);  \\n\\\\- Number of active UEs;  \\n\\\\- Radio Resource Status (per cell PRB usage: UL/DL GBR PRB usage for\\nMIMO, DL/UL non-GBR PRB usage for MIMO, DL/UL total PRB usage for MIMO).  \\nNGAP procedures used for inter-system load balancing are Uplink RAN\\nConfiguration Transfer and Downlink RAN Configuration Transfer.  \\nS1AP procedures used for inter-system load balancing are eNB\\nConfiguration Transfer and MME Configuration Transfer.\\n\\nInformation 2:\\ninformation allowing interoperability between nodes of different\\nvendors;  \\ni\\\\) for the inter-PLMN case, local configuration may restrict the\\nexchange and use of Load Control Information across PLMNs;  \\nj\\\\) the GTP-C node may decide to send different values of Load Control\\nInformation on inter-network (roaming) and on intra-network\\n(non-roaming) interfaces based on local configuration, i.e. the values\\nsent on intra-network interfaces may differ from the values sent on\\ninter-network interfaces. However, on intra-network interfaces, the node\\nshould send the same values between the 3GPP and non-3GPP access based\\ninterfaces.  \\nk\\\\) the Load Control Information received via GTP-C signalling shall be\\nused in conjunction with the information received from the DNS, during\\nthe node selection procedure. Refer to 3GPPTS29.303\\\\[32\\\\] for further\\ndetails.\\n\\nInformation 3:\\ninformation allowing interoperability between nodes of different\\nvendors;  \\ni\\\\) for the inter-PLMN case, local configuration may restrict the\\nexchange and use of Load Control Information across PLMNs;  \\nj\\\\) the GTP-C node may decide to send different values of Load Control\\nInformation on inter-network (roaming) and on intra-network\\n(non-roaming) interfaces based on local configuration, i.e. the values\\nsent on intra-network interfaces may differ from the values sent on\\ninter-network interfaces. However, on intra-network interfaces, the node\\nshould send the same values between the 3GPP and non-3GPP access based\\ninterfaces.  \\nk\\\\) the Load Control Information received via GTP-C signalling shall be\\nused in conjunction with the information received from the DNS, during\\nthe node selection procedure. Refer to 3GPPTS29.303\\\\[32\\\\] for further\\ndetails.\\n\\nInformation 4:\\nTo achieve load reporting function, EN-DC Resource Status Reporting\\nInitiation & EN-DC Resource Status Reporting procedures are used.  \\n##### 22.4.1.2.4 Load reporting for inter-system load balancing  \\nBoth event-triggered and periodic inter-system load reporting are\\nsupported. Event-triggered inter-system load reports are sent when the\\nreporting node detects crossing of cell load thresholds.  \\nThe following load related information should be supported which\\nconsists of:  \\n\\\\- Cell Capacity Class value (UL/DL relative capacity indicator);  \\n\\\\- Capacity value (per cell: UL/DL available capacity);  \\n\\\\- RRC connections (number of RRC connections, and available RRC\\nConnection Capacity);  \\n\\\\- Number of active UEs;  \\n\\\\- Radio Resource Status (per cell PRB usage: UL/DL GBR PRB usage, DL/UL\\nnon-GBR PRB usage, DL/UL total PRB usage, and DL/UL ***scheduling PDCCH\\nCCE usage***).  \\nNGAP procedures used for inter-system load balancing are Uplink RAN\\nConfiguration Transfer and Downlink RAN Configuration Transfer.  \\nS1AP procedures used for inter-system load balancing are eNB\\nConfiguration Transfer and MME Configuration Transfer.  \\n#### 22.4.1.3 Load balancing action based on handovers  \\nThe source cell may initiate handover due to load (see clauses 10.1.2\\nand 10.2.2). The target cell performs admission control for the load\\nbalancing handovers. A handover preparation related to a mobility load\\nbalancing action shall be distinguishable from other handovers, so that\\nthe target cell is able to apply appropriate admission control.  \\n#### 22.4.1.4 Adapting handover and/or reselection configuration  \\nThis function enables requesting of a change of handover and/or\\nreselection parameters at target cell. The source cell that initialized\\nthe load balancing estimates if it is needed to change mobility\\nconfiguration in the source and/or target cell. If the amendment is\\nneeded, the source cell initializes mobility negotiation procedure\\ntoward the target cell.\\n\\nInformation 5:\\nWireline Access Gateway Function (W-AGF). NGAP is used as specified in\\nTS 38.413 \\\\[2\\\\] with clarifications or additions as specified in Clause\\n5.  \\n5 Non-3GPP access\\n=================  \\n5.1 Use of the NGAP for non-3GPP access\\n---------------------------------------  \\nThe following NGAP procedures are used between the Non-3GPP access\\nnetwork node and the AMF:  \\n\\\\- PDU Session Management Procedures  \\n\\\\- PDU Session Resource Setup  \\n\\\\- PDU Session Resource Release  \\n\\\\- PDU Session Resource Modify  \\n\\\\- PDU Session Resource Notify  \\n\\\\- UE Context Management Procedures  \\n\\\\- Initial Context Setup  \\n\\\\- UE Context Release Request  \\n\\\\- UE Context Release  \\n\\\\- UE Context Modification  \\n\\\\- Transport of NAS Messages Procedures  \\n\\\\- Initial UE Message  \\n\\\\- Downlink NAS Transport  \\n\\\\- Uplink NAS Transport  \\n\\\\- NAS Non Delivery Indication  \\n\\\\- Reroute NAS Request  \\n\\\\- Interface Management Procedures  \\n\\\\- NG Setup  \\n\\\\- RAN Configuration Update  \\n\\\\- AMF Configuration Update  \\n\\\\- NG Reset  \\n\\\\- Error Indication  \\n\\\\- AMF Status Indication  \\n\\\\- Overload Start  \\n\\\\- Overload Stop  \\n\\\\- UE TNLA Binding Procedures  \\n\\\\- UE TNLA Binding Release  \\nFor the NGAP procedures used between the Non-3GPP access network node\\nand the AMF, the Non-3GPP access network node fulfils the behaviour of\\nthe NG-RAN node as specified in clause 8 of TS 38.413 \\\\[2\\\\], with\\nclarifications as specified in Clause 5.3. The text in clause 8 of TS\\n38.413 \\\\[2\\\\] referring to Uu should be understood as referring to the Y2\\nreference point as specified in TS 23.501 \\\\[3\\\\].  \\n5.2 NGAP messages used for non-3GPP access\\n------------------------------------------  \\nThe list given below shows the NGAP messages, as specified in TS 38.413\\n\\\\[2\\\\] subclause 9.2 (tabular format) and 9.4  \\n(ASN.1 notation) that are used between the Non-3GPP access network node\\nand the AMF.  \\n\\\\- PDU SESSION RESOURCE SETUP REQUEST  \\n\\\\- PDU SESSION RESOURCE SETUP RESPONSE  \\n\\\\- PDU SESSION RESOURCE RELEASE COMMAND  \\n\\\\- PDU SESSION RESOURCE RELEASE RESPONSE\\n\\nQuestion: Which NGAP procedure is used for inter-system load balancing? [3GPP Release 17]\\nOptions:\\noption 1: eNB Configuration Transfer\\noption 2: Downlink RAN Configuration Transfer\\noption 3: Uplink RAN Configuration Transfer\\noption 4: MME Configuration Transfer\\nThink step by step and choose the correct option.\\nYou must respond in the format 'correct option: <X>', where <X> is the correct letter for the option.assistant\\n\\nAnswer: option 3: Uplink RAN Configuration Transfer\\n\"}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAG_llama_3_2_lora[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to evaluate responses from all models and calculate accuracy\n",
        "def evaluate_accuracy_all_models():\n",
        "    # Evaluate accuracy and collect incorrect question indices for each model\n",
        "    accuracy_llama_3_2_lora, none_llama_3_2_lora, incorrect_llama_3_2_lora = evaluate_accuracy(RAG_llama_3_2_lora)\n",
        "    accuracy_llama_3_2, none_llama_3_2, incorrect_llama_3_2 = evaluate_accuracy(RAG_llama_3_2)\n",
        "    accuracy_gpt4_rag, none_gpt4_rag, incorrect_gpt4_rag = evaluate_accuracy(RAG_gpt4)\n",
        "    accuracy_llama_3_2_lora_no_rag, none_llama_3_2_lora_no_rag, incorrect_llama_3_2_lora_no_rag = evaluate_accuracy(llama_3_2_lora)\n",
        "    accuracy_llama_3_2_no_rag, none_llama_3_2_no_rag, incorrect_llama_3_2_no_rag = evaluate_accuracy(llama_3_2)\n",
        "    accuracy_gpt4_no_rag, none_gpt4_no_rag, incorrect_gpt4_no_rag = evaluate_accuracy(gpt4)\n",
        "\n",
        "    # Store results in a dictionary\n",
        "    results = {\n",
        "        \"RAG llama 3.2 3B Lora\": {\"accuracy\": accuracy_llama_3_2_lora, \"none_count\": none_llama_3_2_lora, \"incorrect_questions\": incorrect_llama_3_2_lora},\n",
        "        \"RAG llama 3.2 3B\": {\"accuracy\": accuracy_llama_3_2, \"none_count\": none_llama_3_2, \"incorrect_questions\": incorrect_llama_3_2},\n",
        "        \"RAG GPT-4o-mini\": {\"accuracy\": accuracy_gpt4_rag, \"none_count\": none_gpt4_rag, \"incorrect_questions\": incorrect_gpt4_rag},\n",
        "        \"Llama 3.2 3B Lora (no RAG)\": {\"accuracy\": accuracy_llama_3_2_lora_no_rag, \"none_count\": none_llama_3_2_lora_no_rag, \"incorrect_questions\": incorrect_llama_3_2_lora_no_rag},\n",
        "        \"Llama 3.2 3B (no RAG)\": {\"accuracy\": accuracy_llama_3_2_no_rag, \"none_count\": none_llama_3_2_no_rag, \"incorrect_questions\": incorrect_llama_3_2_no_rag},\n",
        "        \"GPT-4o-mini (no RAG)\": {\"accuracy\": accuracy_gpt4_no_rag, \"none_count\": none_gpt4_no_rag, \"incorrect_questions\": incorrect_gpt4_no_rag}\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Compare incorrect question indices across models with RAG and without RAG\n",
        "def compare_incorrect_questions(results):\n",
        "    # Extract incorrect question indices for RAG models\n",
        "    rag_incorrect_sets = [\n",
        "        set(results[\"RAG llama 3.2 3B Lora\"][\"incorrect_questions\"]),\n",
        "        set(results[\"RAG llama 3.2 3B\"][\"incorrect_questions\"]),\n",
        "        set(results[\"RAG GPT-4o-mini\"][\"incorrect_questions\"])\n",
        "    ]\n",
        "    \n",
        "    # Extract incorrect question indices for no-RAG models\n",
        "    no_rag_incorrect_sets = [\n",
        "        set(results[\"Llama 3.2 3B Lora (no RAG)\"][\"incorrect_questions\"]),\n",
        "        set(results[\"Llama 3.2 3B (no RAG)\"][\"incorrect_questions\"]),\n",
        "        set(results[\"GPT-4o-mini (no RAG)\"][\"incorrect_questions\"])\n",
        "    ]\n",
        "\n",
        "    # Find common incorrect question indices across RAG models\n",
        "    common_incorrect_rag = sorted(set.intersection(*rag_incorrect_sets))\n",
        "    # Find common incorrect question indices across no-RAG models\n",
        "    common_incorrect_no_rag = sorted(set.intersection(*no_rag_incorrect_sets))\n",
        "\n",
        "    return common_incorrect_rag, len(common_incorrect_rag), common_incorrect_no_rag, len(common_incorrect_no_rag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary of all models' accuracy:\n",
            "RAG llama 3.2 3B Lora - Accuracy: 77.00%, 'None' responses: 0\n",
            "RAG llama 3.2 3B - Accuracy: 72.00%, 'None' responses: 2\n",
            "RAG GPT-4o-mini - Accuracy: 73.00%, 'None' responses: 0\n",
            "Llama 3.2 3B Lora (no RAG) - Accuracy: 48.00%, 'None' responses: 0\n",
            "Llama 3.2 3B (no RAG) - Accuracy: 42.00%, 'None' responses: 2\n",
            "GPT-4o-mini (no RAG) - Accuracy: 58.00%, 'None' responses: 0\n",
            "\n",
            "Common incorrect question indices across RAG models:\n",
            "[4, 14, 18, 19, 31, 37, 57, 59, 69, 86, 90, 93, 94, 99]\n",
            "Total common incorrect questions in RAG models: 14\n",
            "\n",
            "Common incorrect question indices across no-RAG models:\n",
            "[0, 6, 11, 14, 18, 19, 26, 39, 42, 52, 54, 55, 56, 59, 61, 63, 67, 69, 73, 75, 86, 90, 94]\n",
            "Total common incorrect questions in no-RAG models: 23\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation and compare incorrect questions\n",
        "accuracy_results = evaluate_accuracy_all_models()\n",
        "common_incorrect_rag, common_count_rag, common_incorrect_no_rag, common_count_no_rag = compare_incorrect_questions(accuracy_results)\n",
        "\n",
        "# Display summary of accuracy results\n",
        "print(\"\\nSummary of all models' accuracy:\")\n",
        "for model_name, result in accuracy_results.items():\n",
        "    print(f\"{model_name} - Accuracy: {result['accuracy']:.2f}%, 'None' responses: {result['none_count']}\")\n",
        "\n",
        "# Display common incorrect question indices and their counts for RAG and no-RAG models\n",
        "print(\"\\nCommon incorrect question indices across RAG models:\")\n",
        "print(common_incorrect_rag)\n",
        "print(f\"Total common incorrect questions in RAG models: {common_count_rag}\")\n",
        "\n",
        "print(\"\\nCommon incorrect question indices across no-RAG models:\")\n",
        "print(common_incorrect_no_rag)\n",
        "print(f\"Total common incorrect questions in no-RAG models: {common_count_no_rag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_accuracies(accuracy_results):\n",
        "    \"\"\"\n",
        "    Plot a bar chart comparing the accuracies of different models, with all bars in gray.\n",
        "    \"\"\"\n",
        "    # Extract model names and their accuracies\n",
        "    model_names = list(accuracy_results.keys())\n",
        "    accuracies = [result['accuracy'] for result in accuracy_results.values()]\n",
        "    \n",
        "    # Create the bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(model_names, accuracies, color='gray')  # Set all bars to gray\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel(\"Model\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Model Accuracy Comparison\")\n",
        "    plt.ylim(0, 100)  # Set y-axis limit from 0 to 100%\n",
        "    \n",
        "    # Display values above bars\n",
        "    for i, accuracy in enumerate(accuracies):\n",
        "        plt.text(i, accuracy + 1, f\"{accuracy:.2f}%\", ha='center', va='bottom')\n",
        "    \n",
        "    plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to fit all elements\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Call the function with the accuracy results\n",
        "plot_model_accuracies(accuracy_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAGAS Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data from CSV files\n",
        "RAGAS_RAG_llama_3_2_lora = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/llama_3_2_lora_short_answer_RAG_evaluation_RAGAS_LLM.csv\")\n",
        "RAGAS_RAG_llama_3_2 = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/llama_3_2_RAG_evaluation_RAGAS_LLM.csv\")\n",
        "RAGAS_RAG_gpt4 = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/gpt4_RAG_evaluation_RAGAS_LLM.csv\")\n",
        "RAGAS_llama_3_2_lora = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/llama_3_2_lora_short_answer_evaluation_RAGAS_LLM.csv\")\n",
        "RAGAS_llama_3_2 = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/llama_3_2_evaluation_RAGAS_LLM.csv\")\n",
        "RAGAS_gpt4 = pd.read_csv(\"../Evaluations/RAGAS/LLM_evaluation/gpt4_evaluation_RAGAS_LLM.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>semantic_similarity</th>\n",
              "      <th>rubrics_score_with_reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which NGAP procedure is used for inter-system ...</td>\n",
              "      <td>intersystem load balancing procedure.</td>\n",
              "      <td>uplink ran configuration transfer.</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.228364</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is covered by enhanced application layer ...</td>\n",
              "      <td>all of the above.</td>\n",
              "      <td>advanced v2x services.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.113409</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does the Load-Balancing steering mode do?...</td>\n",
              "      <td>divides the traffic of a data flow into two po...</td>\n",
              "      <td>splits the traffic of a data flow across 3gpp ...</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.858245</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the main objective of intent driven ma...</td>\n",
              "      <td>satisfy the new or updated intent.</td>\n",
              "      <td>to reduce the complexity of management for net...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.084886</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does MINT stand for? [3GPP Release 17]</td>\n",
              "      <td>minimization of service interruption.</td>\n",
              "      <td>minimization of service interruption.</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Which RRC state is the UE in when no RRC conne...</td>\n",
              "      <td>inactive.</td>\n",
              "      <td>rrcidle.</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.211736</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>How are the antenna elements placed on each an...</td>\n",
              "      <td>a rectangular arrangement.</td>\n",
              "      <td>in both the vertical and horizontal directions.</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.370383</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>What information may be provided to an emergen...</td>\n",
              "      <td>current dispatchable location if available.</td>\n",
              "      <td>both 1 and 2.</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.125532</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>What is the purpose of cross-network slice coo...</td>\n",
              "      <td>to avoid any interference in the slice communi...</td>\n",
              "      <td>to coordinate network slices in multiple 5g ne...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.488470</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>What does a RedCap UE expect if it monitors PD...</td>\n",
              "      <td>it is only a redcap ue for which the searchspa...</td>\n",
              "      <td>the initial dl bwp to exclude sspbch blocks an...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.259381</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Which NGAP procedure is used for inter-system ...   \n",
              "1   What is covered by enhanced application layer ...   \n",
              "2   What does the Load-Balancing steering mode do?...   \n",
              "3   What is the main objective of intent driven ma...   \n",
              "4         What does MINT stand for? [3GPP Release 17]   \n",
              "..                                                ...   \n",
              "95  Which RRC state is the UE in when no RRC conne...   \n",
              "96  How are the antenna elements placed on each an...   \n",
              "97  What information may be provided to an emergen...   \n",
              "98  What is the purpose of cross-network slice coo...   \n",
              "99  What does a RedCap UE expect if it monitors PD...   \n",
              "\n",
              "                                             response  \\\n",
              "0               intersystem load balancing procedure.   \n",
              "1                                   all of the above.   \n",
              "2   divides the traffic of a data flow into two po...   \n",
              "3                  satisfy the new or updated intent.   \n",
              "4               minimization of service interruption.   \n",
              "..                                                ...   \n",
              "95                                          inactive.   \n",
              "96                         a rectangular arrangement.   \n",
              "97        current dispatchable location if available.   \n",
              "98  to avoid any interference in the slice communi...   \n",
              "99  it is only a redcap ue for which the searchspa...   \n",
              "\n",
              "                                            reference  factual_correctness  \\\n",
              "0                  uplink ran configuration transfer.                 0.00   \n",
              "1                              advanced v2x services.                  NaN   \n",
              "2   splits the traffic of a data flow across 3gpp ...                 0.57   \n",
              "3   to reduce the complexity of management for net...                 0.00   \n",
              "4               minimization of service interruption.                 0.67   \n",
              "..                                                ...                  ...   \n",
              "95                                           rrcidle.                 0.00   \n",
              "96    in both the vertical and horizontal directions.                 0.00   \n",
              "97                                      both 1 and 2.                 0.00   \n",
              "98  to coordinate network slices in multiple 5g ne...                 0.00   \n",
              "99  the initial dl bwp to exclude sspbch blocks an...                 0.00   \n",
              "\n",
              "    semantic_similarity  rubrics_score_with_reference  \n",
              "0              0.228364                             1  \n",
              "1              0.113409                             1  \n",
              "2              0.858245                             3  \n",
              "3              0.084886                             1  \n",
              "4              1.000000                             4  \n",
              "..                  ...                           ...  \n",
              "95             0.211736                             1  \n",
              "96             0.370383                             2  \n",
              "97             0.125532                             2  \n",
              "98             0.488470                             2  \n",
              "99             0.259381                             2  \n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAGAS_RAG_llama_3_2_loraSource/Inference/Inference_RAG_llama_3.2_lora_short_answer.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate means of each DataFrame's columns\n",
        "means_llama_3_2_lora_RAG = RAGAS_RAG_llama_3_2_lora.mean(numeric_only=True)\n",
        "means_llama_3_2_RAG = RAGAS_RAG_llama_3_2.mean(numeric_only=True)\n",
        "means_gpt4_RAG = RAGAS_RAG_gpt4.mean(numeric_only=True)\n",
        "means_llama_3_2_lora_no_RAG = RAGAS_llama_3_2_lora.mean(numeric_only=True)\n",
        "means_llama_3_2_no_RAG = RAGAS_llama_3_2.mean(numeric_only=True)\n",
        "means_gpt4_no_RAG = RAGAS_gpt4.mean(numeric_only=True)\n",
        "\n",
        "# Combine means into a comparative table\n",
        "model_means = pd.DataFrame({\n",
        "    \"RAG llama 3.2 3B Lora\": means_llama_3_2_lora_RAG,\n",
        "    \"RAG llama 3.2 3B\": means_llama_3_2_RAG,\n",
        "    \"RAG GPT-4o-mini\": means_gpt4_RAG,\n",
        "    \"Llama 3.2 3B Lora (no RAG)\": means_llama_3_2_lora_no_RAG,\n",
        "    \"Llama 3.2 3B (no RAG)\": means_llama_3_2_no_RAG,\n",
        "    \"GPT-4o-mini (no RAG)\": means_gpt4_no_RAG\n",
        "}).T  # Transpose to have models as rows and metrics as columns\n",
        "\n",
        "# Round for better readability\n",
        "model_means = model_means.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparative Model Performance with LLM evaluation:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>semantic_similarity</th>\n",
              "      <th>rubrics_score_with_reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG llama 3.2 3B Lora</th>\n",
              "      <td>0.180</td>\n",
              "      <td>0.410</td>\n",
              "      <td>1.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAG llama 3.2 3B</th>\n",
              "      <td>0.141</td>\n",
              "      <td>0.415</td>\n",
              "      <td>2.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAG GPT-4o-mini</th>\n",
              "      <td>0.181</td>\n",
              "      <td>0.421</td>\n",
              "      <td>2.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama 3.2 3B Lora (no RAG)</th>\n",
              "      <td>0.008</td>\n",
              "      <td>0.349</td>\n",
              "      <td>1.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama 3.2 3B (no RAG)</th>\n",
              "      <td>0.078</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GPT-4o-mini (no RAG)</th>\n",
              "      <td>0.061</td>\n",
              "      <td>0.362</td>\n",
              "      <td>2.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            factual_correctness  semantic_similarity  \\\n",
              "RAG llama 3.2 3B Lora                     0.180                0.410   \n",
              "RAG llama 3.2 3B                          0.141                0.415   \n",
              "RAG GPT-4o-mini                           0.181                0.421   \n",
              "Llama 3.2 3B Lora (no RAG)                0.008                0.349   \n",
              "Llama 3.2 3B (no RAG)                     0.078                0.500   \n",
              "GPT-4o-mini (no RAG)                      0.061                0.362   \n",
              "\n",
              "                            rubrics_score_with_reference  \n",
              "RAG llama 3.2 3B Lora                               1.81  \n",
              "RAG llama 3.2 3B                                    2.37  \n",
              "RAG GPT-4o-mini                                     2.53  \n",
              "Llama 3.2 3B Lora (no RAG)                          1.53  \n",
              "Llama 3.2 3B (no RAG)                               1.95  \n",
              "GPT-4o-mini (no RAG)                                2.24  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Comparative Model Performance with LLM evaluation:\")\n",
        "model_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### No LLM Evalaution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data from CSV files\n",
        "RAGAS_RAG_llama_3_2_lora = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/llama_3_2_lora_short_answer_RAG_evaluation_RAGAS_no_LLM.csv\")\n",
        "RAGAS_RAG_llama_3_2 = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/llama_3_2_RAG_evaluation_RAGAS_no_LLM.csv\")\n",
        "RAGAS_RAG_gpt4 = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/gpt4_RAG_evaluation_RAGAS_no_LLM.csv\")\n",
        "RAGAS_llama_3_2_lora = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/llama_3_2_lora_short_answer_evaluation_RAGAS_no_LLM.csv\")\n",
        "RAGAS_llama_3_2 = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/llama_3_2_evaluation_RAGAS_no_LLM.csv\")\n",
        "RAGAS_gpt4 = pd.read_csv(\"../Evaluations/RAGAS/No_LLM_evaluation/gpt4_evaluation_RAGAS_no_LLM.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>bleu_score</th>\n",
              "      <th>rouge_score</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>string_present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which NGAP procedure is used for inter-system ...</td>\n",
              "      <td>intersystem load balancing procedure.</td>\n",
              "      <td>uplink ran configuration transfer.</td>\n",
              "      <td>1.218332e-231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is covered by enhanced application layer ...</td>\n",
              "      <td>all of the above.</td>\n",
              "      <td>advanced v2x services.</td>\n",
              "      <td>1.218332e-231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does the Load-Balancing steering mode do?...</td>\n",
              "      <td>divides the traffic of a data flow into two po...</td>\n",
              "      <td>splits the traffic of a data flow across 3gpp ...</td>\n",
              "      <td>1.469925e-01</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the main objective of intent driven ma...</td>\n",
              "      <td>satisfy the new or updated intent.</td>\n",
              "      <td>to reduce the complexity of management for net...</td>\n",
              "      <td>8.676910e-232</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does MINT stand for? [3GPP Release 17]</td>\n",
              "      <td>minimization of service interruption.</td>\n",
              "      <td>minimization of service interruption.</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Which RRC state is the UE in when no RRC conne...</td>\n",
              "      <td>inactive.</td>\n",
              "      <td>rrcidle.</td>\n",
              "      <td>1.531972e-231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>How are the antenna elements placed on each an...</td>\n",
              "      <td>a rectangular arrangement.</td>\n",
              "      <td>in both the vertical and horizontal directions.</td>\n",
              "      <td>4.739132e-232</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>What information may be provided to an emergen...</td>\n",
              "      <td>current dispatchable location if available.</td>\n",
              "      <td>both 1 and 2.</td>\n",
              "      <td>1.164047e-231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>What is the purpose of cross-network slice coo...</td>\n",
              "      <td>to avoid any interference in the slice communi...</td>\n",
              "      <td>to coordinate network slices in multiple 5g ne...</td>\n",
              "      <td>1.268852e-231</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>What does a RedCap UE expect if it monitors PD...</td>\n",
              "      <td>it is only a redcap ue for which the searchspa...</td>\n",
              "      <td>the initial dl bwp to exclude sspbch blocks an...</td>\n",
              "      <td>5.157007e-155</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Which NGAP procedure is used for inter-system ...   \n",
              "1   What is covered by enhanced application layer ...   \n",
              "2   What does the Load-Balancing steering mode do?...   \n",
              "3   What is the main objective of intent driven ma...   \n",
              "4         What does MINT stand for? [3GPP Release 17]   \n",
              "..                                                ...   \n",
              "95  Which RRC state is the UE in when no RRC conne...   \n",
              "96  How are the antenna elements placed on each an...   \n",
              "97  What information may be provided to an emergen...   \n",
              "98  What is the purpose of cross-network slice coo...   \n",
              "99  What does a RedCap UE expect if it monitors PD...   \n",
              "\n",
              "                                             response  \\\n",
              "0               intersystem load balancing procedure.   \n",
              "1                                   all of the above.   \n",
              "2   divides the traffic of a data flow into two po...   \n",
              "3                  satisfy the new or updated intent.   \n",
              "4               minimization of service interruption.   \n",
              "..                                                ...   \n",
              "95                                          inactive.   \n",
              "96                         a rectangular arrangement.   \n",
              "97        current dispatchable location if available.   \n",
              "98  to avoid any interference in the slice communi...   \n",
              "99  it is only a redcap ue for which the searchspa...   \n",
              "\n",
              "                                            reference     bleu_score  \\\n",
              "0                  uplink ran configuration transfer.  1.218332e-231   \n",
              "1                              advanced v2x services.  1.218332e-231   \n",
              "2   splits the traffic of a data flow across 3gpp ...   1.469925e-01   \n",
              "3   to reduce the complexity of management for net...  8.676910e-232   \n",
              "4               minimization of service interruption.   1.000000e+00   \n",
              "..                                                ...            ...   \n",
              "95                                           rrcidle.  1.531972e-231   \n",
              "96    in both the vertical and horizontal directions.  4.739132e-232   \n",
              "97                                      both 1 and 2.  1.164047e-231   \n",
              "98  to coordinate network slices in multiple 5g ne...  1.268852e-231   \n",
              "99  the initial dl bwp to exclude sspbch blocks an...  5.157007e-155   \n",
              "\n",
              "    rouge_score  exact_match  string_present  \n",
              "0      0.000000          0.0             0.0  \n",
              "1      0.000000          0.0             0.0  \n",
              "2      0.425532          0.0             0.0  \n",
              "3      0.133333          0.0             0.0  \n",
              "4      1.000000          1.0             1.0  \n",
              "..          ...          ...             ...  \n",
              "95     0.000000          0.0             0.0  \n",
              "96     0.000000          0.0             0.0  \n",
              "97     0.000000          0.0             0.0  \n",
              "98     0.166667          0.0             0.0  \n",
              "99     0.142857          0.0             0.0  \n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAGAS_RAG_llama_3_2_lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate means of each DataFrame's columns\n",
        "means_llama_3_2_lora_RAG = RAGAS_RAG_llama_3_2_lora.mean(numeric_only=True)\n",
        "means_llama_3_2_RAG = RAGAS_RAG_llama_3_2.mean(numeric_only=True)\n",
        "means_gpt4_RAG = RAGAS_RAG_gpt4.mean(numeric_only=True)\n",
        "means_llama_3_2_lora_no_RAG = RAGAS_llama_3_2_lora.mean(numeric_only=True)\n",
        "means_llama_3_2_no_RAG = RAGAS_llama_3_2.mean(numeric_only=True)\n",
        "means_gpt4_no_RAG = RAGAS_gpt4.mean(numeric_only=True)\n",
        "\n",
        "# Combine means into a comparative table\n",
        "model_means = pd.DataFrame({\n",
        "    \"RAG llama 3.2 3B Lora\": means_llama_3_2_lora_RAG,\n",
        "    \"RAG llama 3.2 3B\": means_llama_3_2_RAG,\n",
        "    \"RAG GPT-4o-mini\": means_gpt4_RAG,\n",
        "    \"Llama 3.2 3B Lora (no RAG)\": means_llama_3_2_lora_no_RAG,\n",
        "    \"Llama 3.2 3B (no RAG)\": means_llama_3_2_no_RAG,\n",
        "    \"GPT-4o-mini (no RAG)\": means_gpt4_no_RAG\n",
        "}).T  # Transpose to have models as rows and metrics as columns\n",
        "\n",
        "# Round for better readability\n",
        "model_means = model_means.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparative Model Performance with LLM evaluation:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bleu_score</th>\n",
              "      <th>rouge_score</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>string_present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG llama 3.2 3B Lora</th>\n",
              "      <td>0.066</td>\n",
              "      <td>0.243</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAG llama 3.2 3B</th>\n",
              "      <td>0.058</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAG GPT-4o-mini</th>\n",
              "      <td>0.039</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama 3.2 3B Lora (no RAG)</th>\n",
              "      <td>0.021</td>\n",
              "      <td>0.183</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama 3.2 3B (no RAG)</th>\n",
              "      <td>0.056</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GPT-4o-mini (no RAG)</th>\n",
              "      <td>0.003</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            bleu_score  rouge_score  exact_match  \\\n",
              "RAG llama 3.2 3B Lora            0.066        0.243         0.06   \n",
              "RAG llama 3.2 3B                 0.058        0.200         0.05   \n",
              "RAG GPT-4o-mini                  0.039        0.197         0.04   \n",
              "Llama 3.2 3B Lora (no RAG)       0.021        0.183         0.02   \n",
              "Llama 3.2 3B (no RAG)            0.056        0.174         0.00   \n",
              "GPT-4o-mini (no RAG)             0.003        0.139         0.00   \n",
              "\n",
              "                            string_present  \n",
              "RAG llama 3.2 3B Lora                 0.07  \n",
              "RAG llama 3.2 3B                      0.05  \n",
              "RAG GPT-4o-mini                       0.04  \n",
              "Llama 3.2 3B Lora (no RAG)            0.02  \n",
              "Llama 3.2 3B (no RAG)                 0.00  \n",
              "GPT-4o-mini (no RAG)                  0.02  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Comparative Model Performance with LLM evaluation:\")\n",
        "model_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifier Statistical Significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confidence Interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modelos e suas respostas\n",
        "models = {\n",
        "    \"RAG llama 3.2 3B Lora\": RAG_llama_3_2_lora,\n",
        "    \"RAG llama 3.2 3B\": RAG_llama_3_2,\n",
        "    \"RAG GPT-4o-mini\": RAG_gpt4,\n",
        "    \"Llama 3.2 3B Lora (no RAG)\": llama_3_2_lora,\n",
        "    \"Llama 3.2 3B (no RAG)\": llama_3_2,\n",
        "    \"GPT-4o-mini (no RAG)\": gpt4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to calculate confidence interval\n",
        "import math\n",
        "\n",
        "def calculate_confidence_interval(accuracy, sample_size, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for a given accuracy and sample size.\n",
        "    \n",
        "    :param accuracy: Accuracy as a percentage (0-100).\n",
        "    :param sample_size: Number of samples used to compute accuracy.\n",
        "    :param confidence_level: Confidence level (default is 0.95 for 95% confidence).\n",
        "    :return: Tuple (lower_bound, upper_bound) of the confidence interval.\n",
        "    \"\"\"\n",
        "    accuracy_proportion = accuracy / 100\n",
        "    z = 1.96 if confidence_level == 0.95 else 1.64  # Default: 95% confidence\n",
        "    std_error = math.sqrt((accuracy_proportion * (1 - accuracy_proportion)) / sample_size)\n",
        "    lower_bound = accuracy_proportion - z * std_error\n",
        "    upper_bound = accuracy_proportion + z * std_error\n",
        "    return max(0, lower_bound), min(1, upper_bound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Function to evaluate models and calculate confidence intervals\n",
        "def evaluate_and_calculate_intervals(models):\n",
        "    \"\"\"\n",
        "    Evaluate accuracy for all models and calculate their confidence intervals.\n",
        "    \n",
        "    :param models: Dictionary with model names as keys and their responses as values.\n",
        "    :return: Dictionary with evaluation results and confidence intervals for each model.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for model_name, responses in models.items():\n",
        "        # Evaluate model accuracy\n",
        "        accuracy, none_count, incorrect_questions = evaluate_accuracy(responses)\n",
        "        sample_size = len(responses)\n",
        "        \n",
        "        # Calculate confidence interval\n",
        "        confidence_interval = calculate_confidence_interval(accuracy, sample_size)\n",
        "        \n",
        "        # Store results\n",
        "        results[model_name] = {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"confidence_interval\": confidence_interval,\n",
        "            \"sample_size\": sample_size,\n",
        "            \"none_count\": none_count\n",
        "        }\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary of all models' accuracy with confidence intervals:\n",
            "RAG llama 3.2 3B Lora - Accuracy: 77.00%, Confidence Interval: [0.6875, 0.8525], Sample Size: 100, 'None' responses: 0\n",
            "RAG llama 3.2 3B - Accuracy: 72.00%, Confidence Interval: [0.6320, 0.8080], Sample Size: 100, 'None' responses: 2\n",
            "RAG GPT-4o-mini - Accuracy: 73.00%, Confidence Interval: [0.6430, 0.8170], Sample Size: 100, 'None' responses: 0\n",
            "Llama 3.2 3B Lora (no RAG) - Accuracy: 48.00%, Confidence Interval: [0.3821, 0.5779], Sample Size: 100, 'None' responses: 0\n",
            "Llama 3.2 3B (no RAG) - Accuracy: 42.00%, Confidence Interval: [0.3233, 0.5167], Sample Size: 100, 'None' responses: 2\n",
            "GPT-4o-mini (no RAG) - Accuracy: 58.00%, Confidence Interval: [0.4833, 0.6767], Sample Size: 100, 'None' responses: 0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate models and calculate confidence intervals\n",
        "evaluation_results = evaluate_and_calculate_intervals(models)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSummary of all models' accuracy with confidence intervals:\")\n",
        "for model_name, result in evaluation_results.items():\n",
        "    lower, upper = result[\"confidence_interval\"]\n",
        "    print(f\"{model_name} - Accuracy: {result['accuracy']:.2f}%, Confidence Interval: [{lower:.4f}, {upper:.4f}], Sample Size: {result['sample_size']}, 'None' responses: {result['none_count']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## McNema Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import binomtest, chi2\n",
        "\n",
        "def calculate_mcnemar_test_from_indices(model1_incorrect, model2_incorrect, total_questions):\n",
        "    \"\"\"\n",
        "    Perform McNemar's test based on incorrect question indices.\n",
        "    \n",
        "    :param model1_incorrect: Set of incorrect question indices for model 1.\n",
        "    :param model2_incorrect: Set of incorrect question indices for model 2.\n",
        "    :param total_questions: Total number of questions evaluated.\n",
        "    :return: Dictionary with McNemar test results.\n",
        "    \"\"\"\n",
        "    # Calculate contingency table values\n",
        "    b = len(model1_incorrect - model2_incorrect)  # Incorrect in model 1 but correct in model 2\n",
        "    c = len(model2_incorrect - model1_incorrect)  # Correct in model 1 but incorrect in model 2\n",
        "\n",
        "    total_disagreements = b + c\n",
        "\n",
        "    if total_disagreements == 0:\n",
        "        return {\n",
        "            \"chi2_statistic\": None,\n",
        "            \"p_value\": 1.0,\n",
        "            \"result\": \"No disagreements found; models perform identically.\",\n",
        "            \"b\": b,\n",
        "            \"c\": c,\n",
        "            \"total_disagreements\": total_disagreements\n",
        "        }\n",
        "\n",
        "    # Calculate chi-squared statistic and p-value\n",
        "    if total_disagreements > 25:\n",
        "        # Chi-squared approximation\n",
        "        chi2_statistic = ((abs(b - c) - 1) ** 2) / (b + c) if (b + c) > 0 else 0\n",
        "        p_value = chi2.sf(chi2_statistic, df=1)\n",
        "        test_method = \"Chi-squared approximation\"\n",
        "    else:\n",
        "        # Binomial test (exact)\n",
        "        p_value = binomtest(b, n=total_disagreements, p=0.5).pvalue\n",
        "        chi2_statistic = None\n",
        "        test_method = \"Binomial exact test\"\n",
        "\n",
        "    # Checking if the difference is significant based on chi-squared test (critical value 3.841 for 95% confidence)\n",
        "    chi2_critical_value = 3.841\n",
        "    is_significant = chi2_statistic > chi2_critical_value if chi2_statistic is not None else p_value < 0.05\n",
        "\n",
        "    return {\n",
        "        \"chi2_statistic\": chi2_statistic,\n",
        "        \"p_value\": p_value,\n",
        "        \"result\": \"Significant difference\" if is_significant else \"No significant difference\",\n",
        "        \"b\": b,\n",
        "        \"c\": c,\n",
        "        \"total_disagreements\": total_disagreements,\n",
        "        \"test_method\": test_method,\n",
        "        \"is_significant\": is_significant,\n",
        "        \"chi2_critical_value\": chi2_critical_value\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "McNemar's Test Results (RAG llama 3.2 3B Lora vs RAG llama 3.2 3B):\n",
            "Method: Binomial exact test\n",
            "Chi2 Statistic: None\n",
            "P-value: 0.2265625\n",
            "Result: No significant difference\n",
            "b (Lora incorrect, llama correct): 3\n",
            "c (Llama incorrect, Lora correct): 8\n",
            "Total disagreements: 11\n",
            "\n",
            "McNemar's Test Results (RAG llama 3.2 3B Lora vs RAG GPT-4o-mini):\n",
            "Method: Binomial exact test\n",
            "Chi2 Statistic: None\n",
            "P-value: 0.5034446716308594\n",
            "Result: No significant difference\n",
            "b (Lora incorrect, GPT-4 correct): 8\n",
            "c (GPT-4 incorrect, Lora correct): 12\n",
            "Total disagreements: 20\n"
          ]
        }
      ],
      "source": [
        "# Example usage with your existing code\n",
        "accuracy_results = evaluate_accuracy_all_models()\n",
        "\n",
        "# Extract incorrect question sets\n",
        "rag_llama_lora_incorrect = set(accuracy_results[\"RAG llama 3.2 3B Lora\"][\"incorrect_questions\"])\n",
        "rag_llama_incorrect = set(accuracy_results[\"RAG llama 3.2 3B\"][\"incorrect_questions\"])\n",
        "rag_gpt4_incorrect = set(accuracy_results[\"RAG GPT-4o-mini\"][\"incorrect_questions\"])\n",
        "\n",
        "# Total number of questions evaluated\n",
        "total_questions = len(llama_3_2_lora)  # Adjust to match your dataset structure\n",
        "\n",
        "# Perform McNemar's test between models\n",
        "mcnemar_llama_lora_vs_llama = calculate_mcnemar_test_from_indices(\n",
        "    rag_llama_lora_incorrect,\n",
        "    rag_llama_incorrect,\n",
        "    total_questions\n",
        ")\n",
        "\n",
        "mcnemar_llama_lora_vs_gpt4 = calculate_mcnemar_test_from_indices(\n",
        "    rag_llama_lora_incorrect,\n",
        "    rag_gpt4_incorrect,\n",
        "    total_questions\n",
        ")\n",
        "\n",
        "# Display McNemar test results\n",
        "print(\"\\nMcNemar's Test Results (RAG llama 3.2 3B Lora vs RAG llama 3.2 3B):\")\n",
        "print(f\"Method: {mcnemar_llama_lora_vs_llama['test_method']}\")\n",
        "print(f\"Chi2 Statistic: {mcnemar_llama_lora_vs_llama['chi2_statistic']}\")\n",
        "print(f\"P-value: {mcnemar_llama_lora_vs_llama['p_value']}\")\n",
        "print(f\"Result: {mcnemar_llama_lora_vs_llama['result']}\")\n",
        "print(f\"b (Lora incorrect, llama correct): {mcnemar_llama_lora_vs_llama['b']}\")\n",
        "print(f\"c (Llama incorrect, Lora correct): {mcnemar_llama_lora_vs_llama['c']}\")\n",
        "print(f\"Total disagreements: {mcnemar_llama_lora_vs_llama['total_disagreements']}\")\n",
        "\n",
        "print(\"\\nMcNemar's Test Results (RAG llama 3.2 3B Lora vs RAG GPT-4o-mini):\")\n",
        "print(f\"Method: {mcnemar_llama_lora_vs_gpt4['test_method']}\")\n",
        "print(f\"Chi2 Statistic: {mcnemar_llama_lora_vs_gpt4['chi2_statistic']}\")\n",
        "print(f\"P-value: {mcnemar_llama_lora_vs_gpt4['p_value']}\")\n",
        "print(f\"Result: {mcnemar_llama_lora_vs_gpt4['result']}\")\n",
        "print(f\"b (Lora incorrect, GPT-4 correct): {mcnemar_llama_lora_vs_gpt4['b']}\")\n",
        "print(f\"c (GPT-4 incorrect, Lora correct): {mcnemar_llama_lora_vs_gpt4['c']}\")\n",
        "print(f\"Total disagreements: {mcnemar_llama_lora_vs_gpt4['total_disagreements']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## McNemar test 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import binomtest, chi2\n",
        "\n",
        "def calculate_mcnemar_test_from_indices(model1_incorrect, model2_incorrect, total_questions):\n",
        "    \"\"\"\n",
        "    Perform McNemar's test based on incorrect question indices.\n",
        "    \n",
        "    :param model1_incorrect: Set of incorrect question indices for model 1.\n",
        "    :param model2_incorrect: Set of incorrect question indices for model 2.\n",
        "    :param total_questions: Total number of questions evaluated.\n",
        "    :return: Dictionary with McNemar test results.\n",
        "    \"\"\"\n",
        "    # Calculate contingency table values\n",
        "    b = len(model1_incorrect - model2_incorrect)  # Incorrect in model 1 but correct in model 2\n",
        "    c = len(model2_incorrect - model1_incorrect)  # Correct in model 1 but incorrect in model 2\n",
        "\n",
        "    total_disagreements = b + c\n",
        "\n",
        "    # If no disagreements, return early\n",
        "    if total_disagreements == 0:\n",
        "        return {\n",
        "            \"chi2_statistic\": None,\n",
        "            \"p_value_chi2\": None,\n",
        "            \"p_value_binom\": 1.0,\n",
        "            \"result\": \"No disagreements found; models perform identically.\",\n",
        "            \"b\": b,\n",
        "            \"c\": c,\n",
        "            \"total_disagreements\": total_disagreements\n",
        "        }\n",
        "\n",
        "    # Chi-squared test calculation\n",
        "    chi2_statistic = ((abs(b - c) - 1) ** 2) / (b + c) if (b + c) > 0 else 0\n",
        "    p_value_chi2 = chi2.sf(chi2_statistic, df=1)\n",
        "\n",
        "    # Binomial test calculation (exact test)\n",
        "    p_value_binom = binomtest(b, n=total_disagreements, p=0.5).pvalue\n",
        "\n",
        "    # Checking significance based on chi-squared test (critical value 3.841 for 95% confidence)\n",
        "    chi2_critical_value = 3.841\n",
        "    is_significant_chi2 = chi2_statistic > chi2_critical_value\n",
        "    is_significant_binom = p_value_binom < 0.05\n",
        "\n",
        "    result_chi2 = f\"Significant difference (Chi-squared statistic > {chi2_critical_value})\" if is_significant_chi2 else f\"No significant difference (Chi-squared statistic ≤ {chi2_critical_value})\"\n",
        "    result_binom = f\"Significant difference (p-value < 0.05)\" if is_significant_binom else f\"No significant difference (p-value ≥ 0.05)\"\n",
        "\n",
        "    return {\n",
        "        \"chi2_statistic\": chi2_statistic,\n",
        "        \"p_value_chi2\": p_value_chi2,\n",
        "        \"p_value_binom\": p_value_binom,\n",
        "        \"b\": b,\n",
        "        \"c\": c,\n",
        "        \"total_disagreements\": total_disagreements,\n",
        "        \"is_significant_chi2\": is_significant_chi2,\n",
        "        \"is_significant_binom\": is_significant_binom,\n",
        "        \"chi2_critical_value\": chi2_critical_value,\n",
        "        \"result_chi2\": result_chi2,\n",
        "        \"result_binom\": result_binom\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "McNemar's Test Results (RAG llama 3.2 3B Lora vs RAG llama 3.2 3B):\n",
            "Method: Chi-squared and Binomial tests calculated\n",
            "Chi2 Statistic: 1.4545454545454546\n",
            "P-value (Chi-squared): 0.22779999398822554\n",
            "Chi-squared result: No significant difference (Chi-squared statistic ≤ 3.841)\n",
            "P-value (Binomial): 0.2265625\n",
            "Binomial result: No significant difference (p-value ≥ 0.05)\n",
            "b (Lora incorrect, llama correct): 3\n",
            "c (Llama incorrect, Lora correct): 8\n",
            "Total disagreements: 11\n",
            "\n",
            "McNemar's Test Results (RAG llama 3.2 3B Lora vs RAG GPT-4o-mini):\n",
            "Method: Chi-squared and Binomial tests calculated\n",
            "Chi2 Statistic: 0.45\n",
            "P-value (Chi-squared): 0.502334954360502\n",
            "Chi-squared result: No significant difference (Chi-squared statistic ≤ 3.841)\n",
            "P-value (Binomial): 0.5034446716308594\n",
            "Binomial result: No significant difference (p-value ≥ 0.05)\n",
            "b (Lora incorrect, GPT-4 correct): 8\n",
            "c (GPT-4 incorrect, Lora correct): 12\n",
            "Total disagreements: 20\n",
            "\n",
            "The Binomial exact test is more appropriate for the RAG llama 3.2 3B Lora vs RAG llama 3.2 3B comparison because there are 25 or fewer disagreements.\n",
            "The Binomial exact test is more appropriate for the RAG llama 3.2 3B Lora vs RAG GPT-4o-mini comparison because there are 25 or fewer disagreements.\n"
          ]
        }
      ],
      "source": [
        "# Example usage with your existing code\n",
        "accuracy_results = evaluate_accuracy_all_models()\n",
        "\n",
        "# Extract incorrect question sets\n",
        "rag_llama_lora_incorrect = set(accuracy_results[\"RAG llama 3.2 3B Lora\"][\"incorrect_questions\"])\n",
        "rag_llama_incorrect = set(accuracy_results[\"RAG llama 3.2 3B\"][\"incorrect_questions\"])\n",
        "rag_gpt4_incorrect = set(accuracy_results[\"RAG GPT-4o-mini\"][\"incorrect_questions\"])\n",
        "\n",
        "# Total number of questions evaluated\n",
        "total_questions = len(llama_3_2_lora)  # Adjust to match your dataset structure\n",
        "\n",
        "# Perform McNemar's test between models\n",
        "mcnemar_llama_lora_vs_llama = calculate_mcnemar_test_from_indices(\n",
        "    rag_llama_lora_incorrect,\n",
        "    rag_llama_incorrect,\n",
        "    total_questions\n",
        ")\n",
        "\n",
        "mcnemar_llama_lora_vs_gpt4 = calculate_mcnemar_test_from_indices(\n",
        "    rag_llama_lora_incorrect,\n",
        "    rag_gpt4_incorrect,\n",
        "    total_questions\n",
        ")\n",
        "\n",
        "# Display McNemar test results\n",
        "print(\"\\nMcNemar's Test Results (RAG llama 3.2 3B Lora vs RAG llama 3.2 3B):\")\n",
        "print(f\"Method: Chi-squared and Binomial tests calculated\")\n",
        "print(f\"Chi2 Statistic: {mcnemar_llama_lora_vs_llama['chi2_statistic']}\")\n",
        "print(f\"P-value (Chi-squared): {mcnemar_llama_lora_vs_llama['p_value_chi2']}\")\n",
        "print(f\"Chi-squared result: {mcnemar_llama_lora_vs_llama['result_chi2']}\")\n",
        "print(f\"P-value (Binomial): {mcnemar_llama_lora_vs_llama['p_value_binom']}\")\n",
        "print(f\"Binomial result: {mcnemar_llama_lora_vs_llama['result_binom']}\")\n",
        "print(f\"b (Lora incorrect, llama correct): {mcnemar_llama_lora_vs_llama['b']}\")\n",
        "print(f\"c (Llama incorrect, Lora correct): {mcnemar_llama_lora_vs_llama['c']}\")\n",
        "print(f\"Total disagreements: {mcnemar_llama_lora_vs_llama['total_disagreements']}\")\n",
        "\n",
        "print(\"\\nMcNemar's Test Results (RAG llama 3.2 3B Lora vs RAG GPT-4o-mini):\")\n",
        "print(f\"Method: Chi-squared and Binomial tests calculated\")\n",
        "print(f\"Chi2 Statistic: {mcnemar_llama_lora_vs_gpt4['chi2_statistic']}\")\n",
        "print(f\"P-value (Chi-squared): {mcnemar_llama_lora_vs_gpt4['p_value_chi2']}\")\n",
        "print(f\"Chi-squared result: {mcnemar_llama_lora_vs_gpt4['result_chi2']}\")\n",
        "print(f\"P-value (Binomial): {mcnemar_llama_lora_vs_gpt4['p_value_binom']}\")\n",
        "print(f\"Binomial result: {mcnemar_llama_lora_vs_gpt4['result_binom']}\")\n",
        "print(f\"b (Lora incorrect, GPT-4 correct): {mcnemar_llama_lora_vs_gpt4['b']}\")\n",
        "print(f\"c (GPT-4 incorrect, Lora correct): {mcnemar_llama_lora_vs_gpt4['c']}\")\n",
        "print(f\"Total disagreements: {mcnemar_llama_lora_vs_gpt4['total_disagreements']}\")\n",
        "\n",
        "# Determining which test is more appropriate\n",
        "if mcnemar_llama_lora_vs_llama['total_disagreements'] > 25:\n",
        "    print(\"\\nThe Chi-squared test is more appropriate for the RAG llama 3.2 3B Lora vs RAG llama 3.2 3B comparison because there are more than 25 disagreements.\")\n",
        "else:\n",
        "    print(\"\\nThe Binomial exact test is more appropriate for the RAG llama 3.2 3B Lora vs RAG llama 3.2 3B comparison because there are 25 or fewer disagreements.\")\n",
        "\n",
        "if mcnemar_llama_lora_vs_gpt4['total_disagreements'] > 25:\n",
        "    print(\"The Chi-squared test is more appropriate for the RAG llama 3.2 3B Lora vs RAG GPT-4o-mini comparison because there are more than 25 disagreements.\")\n",
        "else:\n",
        "    print(\"The Binomial exact test is more appropriate for the RAG llama 3.2 3B Lora vs RAG GPT-4o-mini comparison because there are 25 or fewer disagreements.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
